{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2695740",
   "metadata": {},
   "source": [
    "<b>Sample Text: The Nile River </b>   \n",
    "Nile, the longest river in the world, is one of the most important parts of Egypt to date. The river is 6695 km long and runs through the countries of Tanzania, Uganda, the Democratic Republic of the Congo, Rwanda, Burundi, Ethiopia, Kenya, Eritrea, South Sudan, Sudan, and Egypt.  \n",
    "The Nile has two main streams that are much smaller, these streams are called the White Nile and the Blue Nile. The history of the Nile is very important as around 5000 years ago the ancient Egyptians relied on the Nile as a source of fresh water, food, and transportation. During the inundation season which was during august the Nile almost always flooded which was a good and bad thing.  \n",
    "However, nowadays the Nile does not flood anymore since in 1970 the Aswan high dam was built which allowed the flood water to be used as water for homes. The Nile provided things like freshwater for drinking, beer making, cooking, washing items and irrigation. Lots of wildlife lived in the river such as fish, birds, frogs, crocodiles, eels, hippopotamus and snakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe21f187",
   "metadata": {},
   "source": [
    "**Question: Which is the world's longest river?**  \n",
    "a) _____   \n",
    "b) Nile  \n",
    "c) ____  \n",
    "d) ____  \n",
    "\n",
    "<hr>  \n",
    "Nile --> Distractor generation algorithms --> Amazon, Missisipi. Yangtze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12b34cc",
   "metadata": {},
   "source": [
    "## 1) Using WordNet to generate distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa58fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d303a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\samra\\appdata\\roaming\\python\\python311\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\samra\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\samra\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\samra\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samra\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\samra\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb980fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\samra\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f62e6",
   "metadata": {},
   "source": [
    "**#single synset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b7db82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('nile.n.01') : the world's longest river (4150 miles); flows northward through eastern Africa into the Mediterranean; the Nile River valley in Egypt was the site of the world's first great civilization\n"
     ]
    }
   ],
   "source": [
    "word = 'nile'\n",
    "word = word.lower()\n",
    "synset = wn.synsets(word)\n",
    "\n",
    "for syn in synset:\n",
    "    print(syn, \":\", syn.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f3173",
   "metadata": {},
   "source": [
    "**#multiple synsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30b7bdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bat.n.01') : nocturnal mouselike mammal with forelimbs modified to form membranous wings and anatomical adaptations for echolocation by which they navigate \n",
      "\n",
      "Synset('bat.n.02') : (baseball) a turn trying to get a hit \n",
      "\n",
      "Synset('squash_racket.n.01') : a small racket with a long handle used for playing squash \n",
      "\n",
      "Synset('cricket_bat.n.01') : the club used in playing cricket \n",
      "\n",
      "Synset('bat.n.05') : a club used for hitting a ball in various games \n",
      "\n",
      "Synset('bat.v.01') : strike with, or as if with a baseball bat \n",
      "\n",
      "Synset('bat.v.02') : wink briefly \n",
      "\n",
      "Synset('bat.v.03') : have a turn at bat \n",
      "\n",
      "Synset('bat.v.04') : use a bat \n",
      "\n",
      "Synset('cream.v.02') : beat thoroughly and conclusively in a competition or fight \n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = 'bat'\n",
    "word = word.lower()\n",
    "synset = wn.synsets(word)\n",
    "\n",
    "for syn in synset:\n",
    "    print(syn, \":\", syn.definition(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13949a",
   "metadata": {},
   "source": [
    "**#get only nouns synsets**  \n",
    "\n",
    "**Que: Which of these is a nocturnal animal that flies?**  \n",
    "a) ____  \n",
    "b) ____  \n",
    "c) bat  \n",
    "d) ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a36ceac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bat.n.01') : nocturnal mouselike mammal with forelimbs modified to form membranous wings and anatomical adaptations for echolocation by which they navigate \n",
      "\n",
      "Synset('bat.n.02') : (baseball) a turn trying to get a hit \n",
      "\n",
      "Synset('squash_racket.n.01') : a small racket with a long handle used for playing squash \n",
      "\n",
      "Synset('cricket_bat.n.01') : the club used in playing cricket \n",
      "\n",
      "Synset('bat.n.05') : a club used for hitting a ball in various games \n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = 'bat'\n",
    "word = word.lower()\n",
    "synset = wn.synsets(word, 'n') # 'n' -> noun\n",
    "\n",
    "for syn in synset:\n",
    "    print(syn, \":\", syn.definition(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6bdc40",
   "metadata": {},
   "source": [
    "**#Get hypernyms for a synset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e02bb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('lion.n.01'), Synset('lion.n.02'), Synset('leo.n.01'), Synset('leo.n.03')]\n",
      "[Synset('big_cat.n.01')]\n",
      "[Synset('feline.n.01')]\n"
     ]
    }
   ],
   "source": [
    "word = 'lion'\n",
    "word = word.lower()\n",
    "synset = wn.synsets(word, 'n')\n",
    "\n",
    "print(synset)\n",
    "hypernym = synset[0].hypernyms()\n",
    "print(hypernym)\n",
    "print(hypernym[0].hypernyms())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07719128",
   "metadata": {},
   "source": [
    "**#Distractors from wordnet**  \n",
    "Co-hyponyms are words that share the same hypernym and have a similar semantic field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4ff94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distractors_wordnet(syn, word):\n",
    "    \n",
    "    distractors = []\n",
    "    word = word.lower()\n",
    "    org_word = word\n",
    "    \n",
    "    if len(word.split()) > 0:\n",
    "        word = word.replace(\" \", \"_\")\n",
    "    \n",
    "    hypernym = syn.hypernyms()\n",
    "    \n",
    "    if len(hypernym) == 0:\n",
    "        return distractors\n",
    "    \n",
    "    for item in hypernym[0].hyponyms():\n",
    "        name = item.lemmas()[0].name()\n",
    "        \n",
    "        if name == org_word:\n",
    "            continue\n",
    "        \n",
    "        name = name.replace(\"_\", \" \")\n",
    "        name = \" \".join(i.capitalize() for i in name.split())\n",
    "        \n",
    "        if name is not None and name not in distractors:\n",
    "            distractors.append(name)\n",
    "    return distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c982a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cohypernyms(word):\n",
    "    synset_to_use = wn.synsets(word, 'n')[0]\n",
    "    distractors_calculated = get_distractors_wordnet(synset_to_use, word)\n",
    "\n",
    "    print(\"Original word:\", word.capitalize())\n",
    "    print(\"Distractors:\", distractors_calculated)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf84a5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word: Lion\n",
      "Distractors: ['Cheetah', 'Jaguar', 'Leopard', 'Liger', 'Saber-toothed Tiger', 'Snow Leopard', 'Tiger', 'Tiglon']\n",
      "\n",
      "Original word: Emperor\n",
      "Distractors: ['Capetian', 'Carolingian', 'Czar', 'King', 'Merovingian', 'Shah']\n",
      "\n",
      "Original word: Sausage\n",
      "Distractors: ['Beef', 'Bird', 'Carbonado', 'Cold Cuts', 'Cut', 'Dark Meat', 'Escargot', 'Game', 'Halal', 'Horsemeat', 'Jerky', 'Lamb', 'Mouton', 'Pemmican', 'Pork', 'Raw Meat', 'Red Meat', 'Sausage Meat', 'Stew Meat', 'Variety Meat', 'Veal']\n",
      "\n",
      "Original word: Blue\n",
      "Distractors: ['Blond', 'Brown', 'Complementary Color', 'Green', 'Olive', 'Orange', 'Pastel', 'Pink', 'Purple', 'Red', 'Salmon', 'Yellow']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_cohypernyms('lion')\n",
    "display_cohypernyms('emperor')\n",
    "display_cohypernyms('sausage')\n",
    "display_cohypernyms('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98080319",
   "metadata": {},
   "source": [
    "**# A word with two different senses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba8add39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaping insect; male makes chirping noises by rubbing the forewings together\n",
      "['Grasshopper'] \n",
      "\n",
      "a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs\n",
      "['Ball Game', 'Field Hockey', 'Football', 'Hurling', 'Lacrosse', 'Polo', 'Pushball', 'Ultimate Frisbee'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = 'cricket'\n",
    "synset = wn.synsets(word, 'n')\n",
    "\n",
    "for syn in synset:\n",
    "    print(syn.definition())\n",
    "    distractors_calculated = get_distractors_wordnet(syn, word)\n",
    "    print(distractors_calculated, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a102515",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60f584",
   "metadata": {},
   "source": [
    "## 2) Using ConceptNet to generate distractors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd4c02",
   "metadata": {},
   "source": [
    "https://conceptnet.io/  \n",
    "\n",
    "**Que: Arnold Schwarzenegger served as a governor to which state?**  \n",
    "a) ____  \n",
    "b) California  \n",
    "c) ____  \n",
    "d) ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ebeb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e866f",
   "metadata": {},
   "source": [
    "api: https://github.com/commonsense/conceptnet5/wiki/API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dcf97af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'@context': ['http://api.conceptnet.io/ld/conceptnet5.7/context.ld.json'],\n",
      " '@id': '/query?node=/c/en/california/n&rel=/r/PartOf&start=/c/en/california',\n",
      " 'edges': [{'@id': '/a/[/r/PartOf/,/c/en/california/n/wn/location/,/c/en/southwest/n/wn/location/]',\n",
      "            '@type': 'Edge',\n",
      "            'dataset': '/d/wordnet/3.1',\n",
      "            'end': {'@id': '/c/en/southwest/n/wn/location',\n",
      "                    '@type': 'Node',\n",
      "                    'label': 'Southwest',\n",
      "                    'language': 'en',\n",
      "                    'sense_label': 'n, location',\n",
      "                    'term': '/c/en/southwest'},\n",
      "            'license': 'cc:by/4.0',\n",
      "            'rel': {'@id': '/r/PartOf', '@type': 'Relation', 'label': 'PartOf'},\n",
      "            'sources': [{'@id': '/s/resource/wordnet/rdf/3.1',\n",
      "                         '@type': 'Source',\n",
      "                         'contributor': '/s/resource/wordnet/rdf/3.1'}],\n",
      "            'start': {'@id': '/c/en/california/n/wn/location',\n",
      "                      '@type': 'Node',\n",
      "                      'label': 'California',\n",
      "                      'language': 'en',\n",
      "                      'sense_label': 'n, location',\n",
      "                      'term': '/c/en/california'},\n",
      "            'surfaceText': '[[California]] is a part of [[Southwest]]',\n",
      "            'weight': 2.0},\n",
      "           {'@id': '/a/[/r/PartOf/,/c/en/california/n/wn/location/,/c/en/united_states/n/wn/location/]',\n",
      "            '@type': 'Edge',\n",
      "            'dataset': '/d/wordnet/3.1',\n",
      "            'end': {'@id': '/c/en/united_states/n/wn/location',\n",
      "                    '@type': 'Node',\n",
      "                    'label': 'United States',\n",
      "                    'language': 'en',\n",
      "                    'sense_label': 'n, location',\n",
      "                    'term': '/c/en/united_states'},\n",
      "            'license': 'cc:by/4.0',\n",
      "            'rel': {'@id': '/r/PartOf', '@type': 'Relation', 'label': 'PartOf'},\n",
      "            'sources': [{'@id': '/s/resource/wordnet/rdf/3.1',\n",
      "                         '@type': 'Source',\n",
      "                         'contributor': '/s/resource/wordnet/rdf/3.1'}],\n",
      "            'start': {'@id': '/c/en/california/n/wn/location',\n",
      "                      '@type': 'Node',\n",
      "                      'label': 'California',\n",
      "                      'language': 'en',\n",
      "                      'sense_label': 'n, location',\n",
      "                      'term': '/c/en/california'},\n",
      "            'surfaceText': '[[California]] is a part of [[United States]]',\n",
      "            'weight': 2.0}],\n",
      " 'version': '5.8.1'}\n"
     ]
    }
   ],
   "source": [
    "word = 'California'\n",
    "word = word.lower()\n",
    "\n",
    "if (len(word.split()) > 0):\n",
    "    word = word.replace(\" \", \"_\")\n",
    "    \n",
    "url = f\"https://api.conceptnet.io/query?node=/c/en/{word}/n&rel=/r/PartOf&start=/c/en/{word}&limit=5\"\n",
    "obj = requests.get(url).json()\n",
    "\n",
    "pprint.pprint(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c6571667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/en/southwest\n",
      "/c/en/united_states\n"
     ]
    }
   ],
   "source": [
    "for edge in obj['edges']:\n",
    "    link = edge['end']['term']\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9aecfed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distractors_conceptnet(word):\n",
    "    word = word.lower()\n",
    "\n",
    "    if (len(word.split()) > 0):\n",
    "        word = word.replace(\" \", \"_\")\n",
    "\n",
    "    url = f\"https://api.conceptnet.io/query?node=/c/en/{word}/n&rel=/r/PartOf&start=/c/en/{word}&limit=5\"\n",
    "    obj = requests.get(url).json()\n",
    "    \n",
    "    for edge in obj['edges']:\n",
    "        link = edge['end']['term']\n",
    "#         print(link)\n",
    "        distractor_list = []\n",
    "\n",
    "        new_url = f\"http://api.conceptnet.io/query?node={link}&rel=/r/PartOf&end={link}&limit=10\"\n",
    "        new_obj = requests.get(new_url).json()\n",
    "\n",
    "        for edge in new_obj['edges']:\n",
    "            new_word = edge['start']['label']\n",
    "\n",
    "            if new_word not in distractor_list and word.lower() not in new_word.lower():\n",
    "                distractor_list.append(new_word)\n",
    "\n",
    "    return distractor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e762d142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nepal\n",
      "['Lebanon', 'Tajikistan', 'Tartary', 'Asian country', 'Roman Empire', 'Qatar', 'Turkistan', 'Tibet', 'Kuwait', 'South Korea']\n"
     ]
    }
   ],
   "source": [
    "word = 'Nepal'\n",
    "print(word)\n",
    "print(get_distractors_conceptnet(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e0e65",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a61868",
   "metadata": {},
   "source": [
    "## 3) Using Wordvectors (sense2vec) to generate distractors  \n",
    "\n",
    "https://github.com/explosion/sense2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4d6ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet sense2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33a017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ae7fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./._s2v_old\n",
      "./s2v_old/\n",
      "./s2v_old/._freqs.json\n",
      "./s2v_old/freqs.json\n",
      "./s2v_old/._vectors\n",
      "./s2v_old/vectors\n",
      "./s2v_old/._cfg\n",
      "./s2v_old/cfg\n",
      "./s2v_old/._strings.json\n",
      "./s2v_old/strings.json\n",
      "./s2v_old/._key2row\n",
      "./s2v_old/key2row\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf s2v_reddit_2015_md.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d603c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg\n",
      "freqs.json\n",
      "key2row\n",
      "strings.json\n",
      "vectors\n"
     ]
    }
   ],
   "source": [
    "!ls s2v_old/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8718a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sense2vec import Sense2Vec\n",
    "s2v = Sense2Vec().from_disk('./s2v_old/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011041a8",
   "metadata": {},
   "source": [
    "**Que: Who is the 45th president of the US?**  \n",
    "a) ____  \n",
    "b) ____  \n",
    "c) ____  \n",
    "d) Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4abff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sense of  donald_trump : Donald_Trump|PERSON\n",
      "Similar word of  donald_trump : [('Sarah_Palin|PERSON', 0.8547), ('Mitt_Romney|PERSON', 0.8246), ('Barrack_Obama|PERSON', 0.8082), ('Bill_Clinton|PERSON', 0.8046), ('Oprah|GPE', 0.8042)]\n"
     ]
    }
   ],
   "source": [
    "word = \"Donald Trump\"\n",
    "word = word.lower()\n",
    "word = word.replace(\" \", \"_\")\n",
    "\n",
    "sense = s2v.get_best_sense(word)\n",
    "print(\"Best sense of \", word, \":\", sense)\n",
    "\n",
    "most_similar = s2v.most_similar(sense, n=5)\n",
    "print(\"Similar word of \", word, \":\", most_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464cbd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sarah Palin', 'Mitt Romney', 'Barrack Obama', 'Bill Clinton', 'Oprah']\n"
     ]
    }
   ],
   "source": [
    "distractors = []\n",
    "\n",
    "for each_word in most_similar:\n",
    "    cleaned_word = each_word[0].split('|')[0].replace(\"_\", \" \").lower()\n",
    "    \n",
    "    if cleaned_word.lower() != word:\n",
    "        distractors.append(cleaned_word.title())\n",
    "\n",
    "print(distractors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613103ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def get_distractors_sense2vec(word, s2v, n=5):\n",
    "    \n",
    "    distractors = []\n",
    "    word = word.lower().replace(\" \", \"_\")\n",
    "    \n",
    "    sense = s2v.get_best_sense(word)\n",
    "    most_similar = s2v.most_similar(sense, n=n)\n",
    "    \n",
    "    for each_word in most_similar:\n",
    "        cleaned_word = each_word[0].split('|')[0].replace(\"_\", \" \").lower()\n",
    "    \n",
    "        if cleaned_word.lower() != word:\n",
    "            distractors.append(cleaned_word.title())\n",
    "    \n",
    "    out = list(OrderedDict.fromkeys(distractors))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c68465d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distractors for Cristiano Ronaldo :\n",
      "['Lionel Messi', 'Wayne Rooney', 'Ronaldo', 'Thierry Henry', 'Messi', 'Gareth Bale', 'Ronaldinho', 'Cristiano']\n"
     ]
    }
   ],
   "source": [
    "word = \"Cristiano Ronaldo\"\n",
    "distractors = get_distractors_sense2vec(word, s2v, 10)\n",
    "\n",
    "print(\"Distractors for\", word, \":\")\n",
    "print(distractors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73afe896",
   "metadata": {},
   "source": [
    "**Using Sentence Transformers to generate unique distractors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac69f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd99d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b554be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distractors_sentencetransformers(answer, candidate_distractors):\n",
    "    \n",
    "    ans = model.encode([answer])\n",
    "    distractors = model.encode(candidate_distractors)\n",
    "    \n",
    "    return ans, distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12dadd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cristiano Ronaldo\n",
      "['Cristiano Ronaldo', 'Lionel Messi', 'Wayne Rooney', 'Ronaldo', 'Thierry Henry', 'Messi', 'Gareth Bale', 'Ronaldinho', 'Cristiano']\n"
     ]
    }
   ],
   "source": [
    "distractors.insert(0, word)\n",
    "print(word)\n",
    "print(distractors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28706847",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_embedded, distractors_embedded = get_distractors_sentencetransformers(word, distractors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a5c52e",
   "metadata": {},
   "source": [
    "**Using Maximum Marginal Relevance algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e751be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmr import MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd7f8f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Cristiano Ronaldo', 1.0), ('Thierry Henry', 0.6863), ('Wayne Rooney', 0.6455), ('Messi', 0.6135), ('Gareth Bale', 0.5344)]\n"
     ]
    }
   ],
   "source": [
    "final_distractors = MMR(answer_embedded, distractors_embedded, distractors, 5)\n",
    "print(final_distractors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8d8cb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cristiano Ronaldo', 'Thierry Henry', 'Wayne Rooney', 'Messi', 'Gareth Bale']\n"
     ]
    }
   ],
   "source": [
    "filtered_distractors = [dist[0] for dist in final_distractors]\n",
    "print(filtered_distractors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2efec1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cristiano Ronaldo\n",
      "-----------------\n",
      "Thierry Henry\n",
      "Wayne Rooney\n",
      "Messi\n",
      "Gareth Bale\n"
     ]
    }
   ],
   "source": [
    "print(filtered_distractors[0])\n",
    "print(\"-----------------\")\n",
    "for x in filtered_distractors[1:]: print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6432f64",
   "metadata": {},
   "source": [
    "****"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
